% Capítulo 2 - Contextualização ou definição do problema


% p. 53 paul taylor tem overview dum sistema tts
% p. 14 dutoit tem diagrama
\chapter{Fundamentação teórica}
\section{Sistemas TTS}
Um sistema \emph{text-to-speech} converte texto em fala.
\subsection{Estrutura}
Na literatura, variações de diagramas. \citeonline{tts-book} propõe um
diagrama geral para sistemas TTS:

\begin{figure}[!htbp]
\centering
\scalebox{0.65}{
    \begin{tikzpicture}[auto, >={Latex[inset=0pt, length=3mm, angle'=28,round]}, box/.style={draw,rounded corners,text width=4.5cm,align=center}]
    \node[] (txt) {Texto};
    \node[box, right=of txt] (nlp)
        {Processamento de linguagem natural};
    \node[box, right=of nlp] (dsp)
        {Processamento digital de sinais};
    \node[right=of dsp] (fal)
        {Fala};

   \node[box, fit=(nlp)(dsp), label=Sistema text-to-speech] (tts) {};

    \draw[->] (txt) -- (nlp);
    \draw[->] (nlp) -- (dsp);
    \draw[->] (dsp) -- (fal);

    \end{tikzpicture}
}
\caption{Arquitetura geral de sistemas TTS (adaptado de \citeonline{tts-book})}
\label{fig:tts-arch}
\end{figure}

É comum encontrar em outros trabalhos a nomenclatura \emph{front end} para o
bloco de processamento de linguagem natural e \emph{back end} para o bloco de
processamento digital de sinais.

\subsection{Normalização de texto}
O texto de entrada pode conter números e símbolos. A primeira parte do processo de conversão de texto para fala é transformar em sua representação por extenso.
Sentence tokenization, isto é, descobrir as boundaries de cada sintagma. Depois,
normalização de palavras não-padrão? abreviações, acrônimos e siglas.
Desambiguação de homônimos heterófonos (e.g.: ``Gosto de pão'')

\subsection{Conversão grafema-fone}
A conversão grafema-fone (ou fonema) consiste em transformar o texto normalizado
em fones, ou seja, uma sequência de caracteres em uma sequência de fones.

\subsection{Geração de prosódia}
A partir do texto e fones gerados nas etapas anteriores, deve-se estimar uma
curva F0, ritmo e ênfase.

\subsection{Síntese de fala}
% martin jurasfky p275
Com o texto de entrada transformado em fones e informação prosódica, um
\emph{back end} é responsável por gerar uma forma de onda.
\citeonline{martinjurafsky} separa algoritmos de síntese em três paradigmas:
síntese concatenativa, síntese por formantes e síntese articulatória. A maioria
dos trabalhos (quais?) recentes trabalham com síntese concatenativa, já que ela
garante resultados mais naturais. Síntese concatenativa pode trabalhar com
diferentes atomicidades: nível de palavra, dífonos e fones individuais.

\section{Prosódia}
\subsection{Componentes}
\citeonline{taylor2009} fala que a prosódia tem:
Stress (loudness and phonatory force)
Syllabic length
F0, intensidade, duração
Intonational tune
Downdrift
Microprosódia
\subsection{Função prosódica}
\subsubsection{Afetiva}
\citeonline{taylor2009} mostra três razões pelas quais utilizamos prosódia na fala.
Prosódia pura, emoção, estado mental e atitude. 
\subsubsection{Supra-segmental}
Características em um discurso neutro, isto é, quando uma sentença é falada sem
conteúdo afetivo significante. \citeonline{taylor2009} fala que em seu modelo de
prosódia a parte supra-segmental não é conteúdo prosódico verdadeiro, mas sim
um outro aspecto do componente verbal.
\subsubsection{Aumentativa}
Um elemento para assegurar a comunicação efetiva do componente verbal de uma mensagem.
\subsection{Prosódia como elemento extra-textual}
% From this we can conclude that in situations where the text genre is quite factual, it is usually sufficient to generate speech from the verbal message only, and so all that is required is the gen- eration of the suprasegmental part of the signal; the affective part of prosody is ignored. In other text genres the situation is significantly more difficult, and if say a dialogue from a play is read in this fashion (or more likely) responses from a computer dialogue system, the generated speech can sound somewhat dull and removed. Finally, we see that mimicking a genuinely good human reader is very difficult indeed, as they will be performing an actual comprehension of the text, and then generating their own prosody. In no way are they simply decoding the prosody from the text and then speaking it aloud, as they can do with the words. To date, no satisfactory solution has been found to this problem, and so current text-to-speech systems are, unfortunately, lacking in this regard.
Considerando o texto como sequência de palavras, é difícil determinar prosódia
afetiva.
Gerar a prosódia certa é uma questão de Natural Language Understanding, isto é,
é preciso entender o texto para gerar os contornos melódicos afetivos.

\subsection{Prosódia em sistemas TTS}
\subsubsection{SSML}
SSML \cite{ssml}, especificação mantida pela W3C.
% https://www.w3.org/TR/emotionml/
MaryTTS usa ToBI, MBROLA, Unit selection do FreeTTS, SSML.
Alexa, Google Assistant e Cortana têm suporte a SSML.
SSML é apenas um modificador (insuficiente para estimar prosódia?)
% http://mary.dfki.de/documentation/overview.html
\subsubsection{EmotionML}
EmotionML \cite{emotionml} foi criada para várias coisas, uma delas