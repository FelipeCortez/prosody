% Capítulo 2 - Contextualização ou definição do problema

% p. 53 paul taylor tem overview dum sistema tts
% p. 14 dutoit tem diagrama
\chapter{Fundamentação teórica}

\section{Prosódia}
\subsection{Componentes}
\cite[p.~150]{cagliari} cita.
Stress (loudness and phonatory force)
Syllabic length
F0, intensidade, duração
Intonational tune
Sintagma entoacional
Além desses componentes principais, \citeonline{taylor2009} descreve downdrift e microprosódia.
\subsection{Função prosódica}
\citeonline{taylor2009} divide a prosódia em três tipos distintos:

\begin{itemize}
\item Afetiva: prosódia pura, emoção, estado mental e atitude. 
\item Suprassegmental: quando uma mensagem é dita de maneira declarativa, sem conteúdo
afetivo significante, dá o nome de \emph{discourse neutral}. utiliza um modelo
de prosódia em que parte supra-segmental não é conteúdo prosódico verdadeiro,
mas sim um outro aspecto do componente verbal.
\item Aumentativa: assegura a comunicação efetiva de uma
mensagem.
\end{itemize}

\subsection{Prosódia como elemento extra-textual}
\citeonline{taylor2009} argumenta que a geração de prosódia afetiva é árdua e
depende de uma compreensão do texto. Ainda fala que, até a data de publicação do
livro, nenhuma solução satisfatória foi encontrada e os sistemas TTS atuais
pecam nesse aspecto.
% Considerando o texto como sequência de palavras, é difícil determinar prosódia
% afetiva.
% Gerar a prosódia certa é uma questão de Natural Language Understanding, isto é,
% é preciso entender o texto para gerar os contornos melódicos afetivos.
% From this we can conclude that in situations where the text genre is quite factual, it is usually sufficient to generate speech from the verbal message only, and so all that is required is the gen- eration of the suprasegmental part of the signal; the affective part of prosody is ignored. In other text genres the situation is significantly more difficult, and if say a dialogue from a play is read in this fashion (or more likely) responses from a computer dialogue system, the generated speech can sound somewhat dull and removed. Finally, we see that mimicking a genuinely good human reader is very difficult indeed, as they will be performing an actual comprehension of the text, and then generating their own prosody. In no way are they simply decoding the prosody from the text and then speaking it aloud, as they can do with the words. To date, no satisfactory solution has been found to this problem, and so current text-to-speech systems are, unfortunately, lacking in this regard.

\section{Sistemas TTS}
\citeonline{ssml} define \emph{text-to-speech} como ``o processo de geração
automática de fala a partir de texto ou texto anotado'' (tradução nossa).
Sistemas TTS são compostos por múltiplos subsistemas, como mostramos a seguir.

\subsection{Estrutura}
Na literatura, encontramos diversas arquiteturas específicas de um sistema TTS.
\citeonline{tts-book} propõe um diagrama geral, dividindo sistemas em duas partes principais:

\begin{figure}[!htbp]
\centering
\scalebox{0.65}{
    \begin{tikzpicture}[auto, >={Latex[inset=0pt, length=3mm, angle'=28,round]}, box/.style={draw,rounded corners,text width=4.5cm,align=center}]
    \node[] (txt) {Texto};
    \node[box, right=of txt] (nlp)
        {Processamento de linguagem natural};
    \node[box, right=of nlp] (dsp)
        {Processamento digital de sinais};
    \node[right=of dsp] (fal)
        {Fala};

        \node[box, fit=(nlp)(dsp), label=Sistema \emph{text-to-speech}] (tts) {};

    \draw[->] (txt) -- (nlp);
    \draw[->] (nlp) -- (dsp);
    \draw[->] (dsp) -- (fal);
    \end{tikzpicture}
}
\caption{Arquitetura geral de sistemas TTS (adaptado de \citeonline{tts-book})}
\label{fig:tts-arch}
\end{figure}
É comum encontrar em outros trabalhos o termo \emph{front end} para o
bloco de processamento de linguagem natural e \emph{back end} para o bloco de
processamento digital de sinais. Doravante utilizaremos essa nomenclatura.

\subsection{\emph{Front end}}

\subsubsection{Normalização de texto}
O texto de entrada pode conter números e símbolos. A primeira parte do processo de conversão de texto para fala é transformar em sua representação por extenso.
Sentence tokenization, isto é, descobrir as boundaries de cada sintagma. Depois,
normalização de palavras não-padrão? abreviações, acrônimos e siglas.
Desambiguação de homônimos heterófonos (e.g.: ``Gosto de pão''). Análise
fonética (normalized word strings para pronúncia).

\subsubsection{Conversão grafema-fone}
Palavras não-padrão são colocadas num dicionário de pronúncia. O resto é
calculado de acordo com regras letra-som.
Context-dependent e independent. Abordagens por machine learning ou regras.
A conversão grafema-fone (ou fonema) consiste em transformar o texto normalizado
em fones, ou seja, uma sequência de caracteres em uma sequência de fones.

\subsubsection{Geração de prosódia}
A partir do texto e fones gerados nas etapas anteriores, deve-se estimar uma
curva F0, ritmo e ênfase.

% decide to use neutral prosody, and the suprasegmental effects that need to be
% synthesised can be found from the verbal part of the message. For more emotive
% messages, or in cases where we think we need significant use of augmentative
% prosody, we have a fairly serious problem. This is because we have no means of
% knowing what prosody the speech should be encoded with; the message that we
% found from the text has no explicit clues as to what the prosody should be.
% (taylor p 37)

% sintagmas entoacionais
%  I wanted to go to London, but could only get tickets for France there seems to be two main intonation phrases, their boundary occurring at the comma
%  there is often a slight drop in F0 from the beginning of an intonation phrase to its end, which resets at the beginning of a new intonation phrase
% A very high-precision rule is the one we saw for sentence segmentation: insert a boundary after punctuation. Another commonly used rule inserts a phrase boundary before a function word following a content word.

\subsection{Back end}
% martin jurasfky p275
Com o texto de entrada transformado em fones e informação prosódica, um
\emph{back end} é responsável por gerar uma forma de onda.
\citeonline{martinjurafsky} separam algoritmos de síntese em três paradigmas:
síntese concatenativa, síntese por formantes e síntese articulatória. 

\begin{itemize}
\item Síntese articulatória
\item Síntese por formantes
\item Síntese concatenativa
Síntese concatenativa pode trabalhar com diferentes atomicidades: nível de palavra,
dífonos e fones individuais.
\end{itemize}

% Intonational phrase: sintagmas entoacionais
% Tone boundary: fronteira prosódica?
% Pitch accent: acento de pitch

% https://www.ime.usp.br/~cpaz/downloads/algorithm-portuguese.pdf

Abordagem utilizada pelo programa MBROLA. Consiste em gravar fala, separar
pedaços de dois em dois.

% http://hts.sp.nitech.ac.jp/
Algumas vozes para o MaryTTS \cite{marytts} utilizam HMMs, isto é, Modelos
ocultos de Markov para \emph{unit selection}. Há, inclusive, uma voz brasileira
feita a partir de HMMs: \cite{couto}.
Projetos mais recentes como \cite{merlin,dnngoogle} utilizam redes neurais para
estimação de parâmetros. O trabalho da Google informa? que a estimação da curva
F0 é uma possível melhoria.
